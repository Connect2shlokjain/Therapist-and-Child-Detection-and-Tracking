{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0d539b-c1c2-45e3-8eb9-a1dba5581c8a",
   "metadata": {},
   "source": [
    "# <font color='red'><b>Disclaimer :</b></font> <i>This is <u> not the real code file </u>, The real code file is Success_1.ipynb this one is made for purpose of Genral Explanation of code and Approach</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681c17f6-c80f-4d8e-a5f9-9e735ed4f17f",
   "metadata": {},
   "source": [
    "## Step 1: Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638bb7cf-952a-4a87-af72-5cf4abf37318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8704e4f-22aa-41ee-afa3-cdff14758ae3",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "Import the required modules for image processing, object detection, data manipulation, and file operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a37d8-393e-4a96-9c6a-247b6291587a",
   "metadata": {},
   "source": [
    "## Step 2: Load the Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bdbcc9-c4f0-4423-af55-e7717da6027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model_url = \"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\"\n",
    "    model = hub.load(model_url)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c4e34c-33fb-4372-bcac-00b5f5af7ebe",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "Define a function to load the pre-trained SSD MobileNet V2 object detection model from TensorFlow Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5df37-87c4-4f4b-a329-ccc6f4dbf83c",
   "metadata": {},
   "source": [
    "## Step 3: Process a Single Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674a732-122f-49eb-b53f-0001e8c2f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, model, output_frame_dir, video_number):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_num = 0\n",
    "    unique_ids = {}\n",
    "    next_id = 1\n",
    "    video_data = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_num += 1\n",
    "\n",
    "        # Skip some frames to reduce processing load\n",
    "        if frame_num % 10 != 0:\n",
    "            continue\n",
    "\n",
    "        # Perform object detection\n",
    "        detections = detect_objects(model, frame)\n",
    "\n",
    "        # Extract person detections\n",
    "        person_detections = []\n",
    "        for i in range(int(detections['num_detections'][0])):\n",
    "            if detections['detection_classes'][0][i].numpy() == 1:  # Class 1 corresponds to 'person'\n",
    "                ymin, xmin, ymax, xmax = detections['detection_boxes'][0][i].numpy()\n",
    "                h, w, _ = frame.shape\n",
    "                person_detections.append([xmin * w, ymin * h, xmax * w, ymax * h])\n",
    "\n",
    "        # Assign unique IDs to detected people\n",
    "        new_unique_ids, next_id = assign_unique_id(person_detections, unique_ids, next_id)\n",
    "\n",
    "        # Save the frames where persons are detected\n",
    "        for detection, uid in zip(person_detections, new_unique_ids.values()):\n",
    "            x1, y1, x2, y2 = detection\n",
    "            person_image = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "            person_image_path = f'{output_frame_dir}/person_{uid}_frame_{frame_num}.jpg'\n",
    "            cv2.imwrite(person_image_path, person_image)\n",
    "\n",
    "            # Collect data for CSV\n",
    "            video_data.append({\n",
    "                'Person ID': uid,\n",
    "                'Image Path': person_image_path,\n",
    "                'Frame Number': frame_num,\n",
    "                'Video Number': video_number,\n",
    "                'Count': 1  # This is just a placeholder; it will be counted later\n",
    "            })\n",
    "\n",
    "    cap.release()\n",
    "    return video_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583cee92-3256-41c5-a4ad-b576b9a21704",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "This function processes a single video, detects people, assigns unique IDs, saves cropped images, and collects data for each detection. It returns a list of data dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f50bd9-fe8c-4b26-badd-af98ddbc6a25",
   "metadata": {},
   "source": [
    "## Step 4: Process All Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b8b01-2824-400e-bfcb-2797702c0dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_videos(videos_dir, frames_dir, model):\n",
    "    all_video_data = []\n",
    "\n",
    "    for video_number, video_file in enumerate(os.listdir(videos_dir), start=1):\n",
    "        video_path = os.path.join(videos_dir, video_file)\n",
    "        video_frames_dir = os.path.join(frames_dir, f\"video_{video_number}_frames\")\n",
    "        os.makedirs(video_frames_dir, exist_ok=True)\n",
    "\n",
    "        # Process video and collect data\n",
    "        video_data = process_video(video_path, model, video_frames_dir, video_number)\n",
    "\n",
    "        # Merge video data into the aggregated list\n",
    "        all_video_data.extend(video_data)\n",
    "\n",
    "    return all_video_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468530f-0b89-49b9-8045-41936b115724",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "This function iterates through all videos in a directory, processes each video using the process_video function, and combines the results into a single list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48981132-22f9-4295-9290-fd4fbd619747",
   "metadata": {},
   "source": [
    "## Step 5: Save Data to CSV / Storing the data in tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a85ff2-bbde-4387-b02c-a61f93a6e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(all_video_data, output_csv_path):\n",
    "    # Create a dictionary to count occurrences of each Person ID\n",
    "    id_counts = {}\n",
    "    for data in all_video_data:\n",
    "        uid = data[\"Person ID\"]\n",
    "        id_counts[uid] = id_counts.get(uid, 0) + 1\n",
    "\n",
    "    # Add count information to each entry\n",
    "    for data in all_video_data:\n",
    "        uid = data[\"Person ID\"]\n",
    "        data[\"Count\"] = id_counts[uid]\n",
    "\n",
    "    # Write all data to a single CSV file\n",
    "    with open(output_csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"Person ID\", \"Image Path\", \"Frame Number\", \"Video Number\", \"Count\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_video_data)\n",
    "\n",
    "    print(f\"CSV file saved at {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab152b-aa7c-46f2-a3af-517622299ad0",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "This function counts the occurrences of each Person ID, adds the count information to each data entry, and writes all data to a single CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297dee78-9c42-413f-a244-bf2a263931bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Paths\n",
    "    videos_dir = r'C:\\Users\\shlok\\OneDrive\\Desktop\\Computer Vision\\Approach 2\\Videos'\n",
    "    frames_dir = r'C:\\Users\\shlok\\OneDrive\\Desktop\\Computer Vision\\Approach 2\\Frames'\n",
    "    output_csv_path = r'C:\\Users\\shlok\\OneDrive\\Desktop\\Computer Vision\\Approach 2\\CSV_Outputs\\detections_summary.csv'\n",
    "\n",
    "    # Load model\n",
    "    model = load_model()\n",
    "\n",
    "    # Process all videos and collect data\n",
    "    all_video_data = process_all_videos(videos_dir, frames_dir, model)\n",
    "\n",
    "    # Save results to a single CSV file\n",
    "    save_to_csv(all_video_data, output_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08f3c01-7f0d-4be3-92e6-f83d2409f321",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "\n",
    "This is the main execution block where you set the paths, load the model, process all videos, and save the results to a CSV file.\n",
    "Additional Notes:\n",
    "\n",
    "Adjust the paths to match your directory structure.\n",
    "You can customize the model URL and other parameters as needed.\n",
    "Consider adding error handling and logging for more robust behavior.\n",
    "You can explore additional features like tracking people across frames or analyzing the collected data further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d77a5d-b6d2-41e9-b8e0-729408dcf275",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2fc89a-6413-43b4-98ca-7d576c9d7565",
   "metadata": {},
   "source": [
    "How I apporach to the problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c432ee6-60e6-4872-949a-547c061d4848",
   "metadata": {},
   "source": [
    "1. I did explore what are the mobles available and choose the best which fits and I have similar experience with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464fc18-5701-4689-933d-5d0e5db0ceff",
   "metadata": {},
   "source": [
    "2. Did explored the mobilenet_v2 model, and understand why this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d12b5d-fec3-4caf-a1a0-d3809e4b35fc",
   "metadata": {},
   "source": [
    "3. Testing with model sample size and work:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa64f4-b4dd-4ec8-abe2-a797f572d817",
   "metadata": {},
   "source": [
    "* Extracted Youtube video and seprated pictures from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98618528-3857-4909-8039-0a66f4034981",
   "metadata": {},
   "source": [
    "* Made OCR model to seprate Frames with humans in it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622afcfe-a189-451f-b2c9-dc4d71a8fd6d",
   "metadata": {},
   "source": [
    "* Since model was getting to complex and highly stroage in enfficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c2bc8c-d1b7-44d7-b116-5defff04855f",
   "metadata": {},
   "source": [
    "* After that I did tweak the data sample without loosing identities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509c53a-f8a5-4439-b67e-ad8e03c9f906",
   "metadata": {},
   "source": [
    "4. Processing the video and data as per given PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7796a9bd-088d-45ec-afef-af07a71c3b7e",
   "metadata": {},
   "source": [
    "5. Prepare the model and load into the Table/csv......"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f4545-0d5d-42b4-a575-45448e1f3380",
   "metadata": {},
   "source": [
    "## What I have learned and explored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553e64f-3840-45e3-8007-f7f9c4d2806e",
   "metadata": {},
   "source": [
    "* Exctration of video, how to handle them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c466fa-b96e-44c8-878f-cf91fd1a1b83",
   "metadata": {},
   "source": [
    "* Loading the existing models and working with that(I did it for the first time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078b286-fb88-40b0-bd3d-5b7bcef0afe9",
   "metadata": {},
   "source": [
    "* New possiblities of promting to learn and explore....."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
